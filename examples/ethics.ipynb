{"nbformat": 4, "nbformat_minor": 2, "metadata": {}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Data Science Ethics Checklist\n", "\n", "## Team Composition\n", "------\n", " - [ ] Does our team reflect diversity of opinions, backgrounds, and kinds of thought?\n", "\n", "## Data Collection\n", "------\n", " - [ ] If there are human subjects, have those subjects have given informed consent, where users clearly understand what they are consenting to and there was a mechanism in place for gathering consent?\n", " - [ ] Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n", " - [ ] Have we ensured that data collection does not collect personally identifable information (PII) which is not relevant to the analysis?\n", " - [ ] Has the data been appropriately anonymized before being stored?\n", "\n", "## Data Storage\n", "------\n", " - [ ] Do we have a plan to protect and secure data (e.g. encryption, up-to-date software)?\n", " - [ ] Have we set up appropriate access controls and means to monitor access?\n", " - [ ] Do we have a mechanism through which an individual can request their personal information be removed?\n", " - [ ] Is there a schedule or plan to delete the data after it is no longer needed?\n", "\n", "## Exploratory Analysis\n", "------\n", " - [ ] Have we studied and understood possible sources of bias in our data?\n", " - [ ] Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n", " - [ ] Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n", " - [ ] Is the process of generating the analysis auditable if we discover issues in the future?\n", "\n", "## Modeling\n", "------\n", " - [ ] Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g. affected community and subject matter experts)?\n", " - [ ] Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminative?\n", " - [ ] Have we tested model results for fairness with respect to different affected groups (e.g. tested for disparate error rates)?\n", " - [ ] Have we considered the effects of the assumptions built into our model and the effects of optimizing for our defined metrics?\n", " - [ ] Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n", "\n", "## Deployment\n", "------\n", " - [ ] Is there a way to turn off or roll back the model in production if necessary?\n", " - [ ] Do we have a mechanism for redress if users are harmed by the results?\n", " - [ ] Do we test and monitor for model drift to ensure it remains fair over time?\n", " - [ ] Have we taken steps to identify and prevent abuse, unintended uses, and malicious attacks on the model?\n", " - [ ] Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n", "\n", "\n"]}]}